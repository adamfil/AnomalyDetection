{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f71ac7",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64cfb5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469522de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../src/data')\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix \n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.inspection import permutation_importance, plot_partial_dependence\n",
    "\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from xml2dict import *\n",
    "from dict2tabular import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a65433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml2soup(xml_path: str):\n",
    "    \"\"\" Loads xml into BeautifulSoup object.\n",
    "\n",
    "    Params:\n",
    "        xml_path (string) - Path to xml to be loaded\n",
    "\n",
    "    Returns:\n",
    "        soup (BeautifulSoup object)\n",
    "    \"\"\"\n",
    "    xml_content = requests.get(xml_path)\n",
    "    soup = BeautifulSoup(xml_content.content, 'lxml')\n",
    "    return soup\n",
    "\n",
    "def xml_extract_metadata(xml_soup):\n",
    "    \"\"\" Extracts metadata for identification (station, time and location) from top of xml.\n",
    "\n",
    "    Params:\n",
    "        output_dict (dict) - Dictionary to add information to\n",
    "        xml_soup (BeautifulSoup object) - beautifulSoup object containing the loaded xml information.\n",
    "\n",
    "    Returns:\n",
    "        output_dict (dict) - Updated dictionary with added metadata information\n",
    "    \"\"\"\n",
    "    output_dict = dict()\n",
    "    identification_elements = xml_soup.find(\"identification-elements\")\n",
    "    id_element_list = ['date_time', 'tc_identifier', 'station_name', 'station_elevation',\n",
    "                       'latitude', 'longitude', 'version', 'correction', 'source_uri']\n",
    "    for id_element in id_element_list:\n",
    "        try:\n",
    "            output_dict[id_element] = identification_elements.findChild(name='element',\n",
    "                                                                        attrs={'name': id_element}\n",
    "                                                                        ).get(\"value\")\n",
    "        except AttributeError as error:\n",
    "            print(error, \". Possibly element '%s' is missing.\" % id_element)\n",
    "\n",
    "    # Station identifier are missing in some xml files\n",
    "    try:\n",
    "        output_dict['station_identifier'] = identification_elements.findChild(name='element',\n",
    "                                                                              attrs={'name': 'station_identifier'}\n",
    "                                                                              ).get(\"value\")\n",
    "    except AttributeError as error:\n",
    "        print('error sigma')\n",
    "\n",
    "    observation_elements = xml_soup.find('om:result').find('elements').findAll('element')\n",
    "    for each_elem in observation_elements:\n",
    "        \n",
    "        try:\n",
    "            if each_elem['element-index']:\n",
    "                \n",
    "                dict_key = each_elem['name']+'_'+each_elem['orig-name']\n",
    "                output_dict[dict_key+'_value'] = each_elem['value']\n",
    "                #print(each_elem['orig-name'])\n",
    "                #print(each_elem['value'])\n",
    "                \n",
    "                qc_soup = each_elem.find('quality-controlled')\n",
    "                qc_summary_dict_key = dict_key+'_'+qc_soup.find('element')['name']\n",
    "                output_dict[qc_summary_dict_key] = qc_soup.find('element')['value']\n",
    "                \n",
    "                # qc native tag\n",
    "                qc_native = qc_soup.find('native').findAll('qualifier')\n",
    "                for each_native in qc_native:\n",
    "                    try:\n",
    "                        output_dict[dict_key+'_'+each_native['name']] = each_native['value']\n",
    "                    except:\n",
    "                        print('error beta')\n",
    "                        continue\n",
    "                \n",
    "                #print(output_dict)\n",
    "                #print(qc_soup.find('real-time'))\n",
    "                qc_element_list = qc_soup.find('real-time').find('element').findAll('element', recursive=False)\n",
    "                #print(qc_element_list)\n",
    "                for each_qc in qc_element_list:\n",
    "                    try:\n",
    "                        qc_dict_key = dict_key+'_qa-'+each_qc['name']\n",
    "                        output_dict[qc_dict_key] = each_qc['value']\n",
    "                    \n",
    "                        qc_detail = each_qc.findAll('element')\n",
    "\n",
    "                        for qc_det_item in qc_detail:\n",
    "                            try:\n",
    "                                qc_det_name = dict_key+'_qc-'+qc_det_item['name']+'_'+qc_det_item['value'].split('/')[6]\n",
    "                                output_dict[qc_det_name] = qc_det_item.find('qualifier', {'name' : 'flag_value'})['value']\n",
    "                            except:\n",
    "                                print(\"error gamma\")\n",
    "                                continue\n",
    "                    except:\n",
    "                        print('error gamma')\n",
    "                        continue\n",
    "        except:\n",
    "\n",
    "            continue\n",
    "       # print(output_dict)\n",
    "\n",
    "    #finally:\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e3c15d",
   "metadata": {},
   "source": [
    "## Import Live Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d68bb7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://dms.cmc.ec.gc.ca:8180/notification?path=/msc/observation/atmospheric/surface_weather/ca-1.1-ascii/decoded_qa_enhanced-xml-2.0&time=1d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run iff you want to look through multiple days on DMS\n",
    "items = []\n",
    "for i in range(1, 6):\n",
    "\n",
    "    content_url = 'http://dms.cmc.ec.gc.ca:8180/notification?path=/msc/observation/atmospheric/surface_weather/ca-1.1-ascii/decoded_qa_enhanced-xml-2.0&time='+str(i)+'d'\n",
    "    print(content_url)\n",
    "    content_data = requests.get(content_url)\n",
    "    html = xml2soup(content_url)\n",
    "    item = html.findAll('item')\n",
    "    print(item)\n",
    "    items.extend(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7753a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#station_id = ['zrp', 'mfj', 'nbi', 'ngh', 'nsg', 'wfz', 'wic', 'wyh', 'xcm', 'zhk', 'zrp', 'eqi']\n",
    "\n",
    "station_id = ['nco', 'nek', 'zrp', 'mfj', 'zpk', 'nbi', 'eqi', 'ngh', 'nsg', 'wfz', 'wyh', 'wkx', 'gah', 'ads', 'wdw', 'wzv', 'wic', 'ndt', 'wsy', 'won', 'way', 'xcm', 'xux', 'xet', 'zlt', 'wij', 'wjc', 'nzs', 'wnv', 'wst', 'zcr', 'zel', 'xbl', 'mfm', 'acq', 'pjm', 'pif', 'who', 'wpz', 'xgd', 'zhk', 'pqw', 'wdv', 'wfp', 'wnz', 'xdi', 'wvt', 'pyq', 'apr', 'xqh', 'xfb', 'wpk', 'nvq', 'wct', 'wzg', 'xmm', 'zcy', 'web', 'wgd', 'xeg', 'vqz', 'xse', 'vxy', 'pqd', 'zvm', 'pzh', 'mjk', 'xox', 'zsm', 'aqy', 'ncd', 'zdb','xrb', 'xqb', 'zhy', 'abf', 'wgr',  'xnp', 'wdc', 'xwf', 'wsk', 'ahr', 'xar', 'zfs', 'wvc', 'xoa', 'ple', 'zsp', 'wtd', 'wrk', 'wsn',  'zhb', 'xmw', 'mrf', 'xto', 'ppr', 'nbb', 'xat', 'erm', 'xhi', 'zka', 'nco', 'adl', 'zoc', 'wyj', 'asb', 'apb', 'xzv', 'xha', 'xzc', 'wwn', 'wcf', 'xka', 'xrg', 'tze', 'wfz', 'zev', 'pgf', 'xtl', 'ybg', 'yyr', 'yod', 'yoj', 'ygq', 'yzt', 'ygl', 'yth', 'yvp', 'yxy', 'otl', 'wch', 'wxp', 'wzt',         ]\n",
    "\n",
    "#station_id = ['nco', 'nek']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "url_list = list()\n",
    "\n",
    "for each in items:\n",
    "\n",
    "    # get url of each observation and ignore supporting xmls (supp_1440)\n",
    "    if each.find('title').contents[0].split('/')[2] in station_id and 'supp_1440' not in each.find('title').contents[0]:\n",
    "        url_list.append(each.contents[2])\n",
    "        #parse url and create a table with each row as observation, and element value as columns\n",
    "        soupu = xml2soup(each.contents[2])\n",
    "        extracted = xml_extract_metadata(soupu)\n",
    "        df = df.append(extracted, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f341fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_time', 'tc_identifier', 'station_name', 'station_elevation',\n",
       "       'latitude', 'longitude', 'version', 'correction', 'source_uri',\n",
       "       'station_identifier',\n",
       "       ...\n",
       "       'cumulative_precipitation_gauge_weight_unfiltered_3020_value',\n",
       "       'cumulative_precipitation_gauge_weight_unfiltered_3020_overall_qa_summary',\n",
       "       'cumulative_precipitation_gauge_weight_unfiltered_3020_error',\n",
       "       'cumulative_precipitation_gauge_weight_unfiltered_3020_suspect',\n",
       "       'cumulative_precipitation_gauge_weight_unfiltered_3020_suppressed',\n",
       "       'cumulative_precipitation_gauge_weight_unfiltered_3021_value',\n",
       "       'cumulative_precipitation_gauge_weight_unfiltered_3021_overall_qa_summary',\n",
       "       'cumulative_precipitation_gauge_weight_unfiltered_3021_error',\n",
       "       'cumulative_precipitation_gauge_weight_unfiltered_3021_suspect',\n",
       "       'cumulative_precipitation_gauge_weight_unfiltered_3021_suppressed'],\n",
       "      dtype='object', length=298)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop if any columns contains null\n",
    "newDf = df.dropna(how='any', axis=1)\n",
    "newDf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d016144c",
   "metadata": {},
   "source": [
    "## Import Trained Snow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95e8f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = read_pickle(file='../anomalydetection/data/processed1/df_snow_depth_3022_2019.pickle')\n",
    "X_2019 = read_pickle(file='../anomalydetection/data/processed1/df_snow_depth_3022_2020.pickle')\n",
    "X_2020 = read_pickle(file='../anomalydetection/data/processed1/df_snow_depth_3022_2021_jan_jun.pickle')\n",
    "\n",
    "Xsnow = pd.concat([X, X_2019], ignore_index=True, sort=False)\n",
    "Xsnow = pd.concat([X, X_2020], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19b78da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsnow = Xsnow.dropna(how='any', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8209fa8",
   "metadata": {},
   "source": [
    "## Import Trained Wind Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7680a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xwind = read_pickle(r'C:\\Users\\filipovicha\\Documents\\AI_Project\\moov-ai-automatic-qc\\data\\processed_before_nf\\wind_speed_3005.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c72115bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xwind = Xwind.dropna(how='any', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6633489b",
   "metadata": {},
   "source": [
    "## Import Trained Precip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "616f7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xprecip = read_pickle(r'C:\\Users\\filipovicha\\Documents\\AI_Project\\moov-ai-automatic-qc\\data\\processed_before_nf\\precipitation_amount_285.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccc7c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xprecip = Xprecip.dropna(how='any', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15acc5a1",
   "metadata": {},
   "source": [
    "## Detect Snow Depth Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f931f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_snow_elems = list(np.intersect1d(Xsnow.columns, newDf.columns))\n",
    "test_real_time = newDf[common_snow_elems] \n",
    "common_snow_elems.append('snow_depth_3022_target')\n",
    "train_real_time = Xsnow[common_snow_elems]\n",
    "train_y = train_real_time['snow_depth_3022_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e945e2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-a09e4313c62b>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_real_time['hour_of_day'] = train_real_time.date_time.dt.hour\n",
      "<ipython-input-25-a09e4313c62b>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_real_time['yearz'] = train_real_time.date_time.dt.year\n",
      "<ipython-input-25-a09e4313c62b>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_real_time['monthz'] = train_real_time.date_time.dt.month\n",
      "<ipython-input-25-a09e4313c62b>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_real_time['dayz'] = train_real_time.date_time.dt.day\n",
      "<ipython-input-25-a09e4313c62b>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_real_time['hour_of_day'] = train_real_time.date_time.dt.hour\n",
      "<ipython-input-25-a09e4313c62b>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_real_time['yearz'] = train_real_time.date_time.dt.year\n",
      "<ipython-input-25-a09e4313c62b>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_real_time['monthz'] = train_real_time.date_time.dt.month\n",
      "<ipython-input-25-a09e4313c62b>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_real_time['dayz'] = train_real_time.date_time.dt.day\n"
     ]
    }
   ],
   "source": [
    "# keeping the the date and time for anomaly detection\n",
    "train_real_time['hour_of_day'] = train_real_time.date_time.dt.hour\n",
    "train_real_time['yearz'] = train_real_time.date_time.dt.year\n",
    "train_real_time['monthz'] = train_real_time.date_time.dt.month\n",
    "train_real_time['dayz'] = train_real_time.date_time.dt.day\n",
    "\n",
    "test_real_time['hour_of_day'] = train_real_time.date_time.dt.hour\n",
    "test_real_time['yearz'] = train_real_time.date_time.dt.year\n",
    "test_real_time['monthz'] = train_real_time.date_time.dt.month\n",
    "test_real_time['dayz'] = train_real_time.date_time.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "579d7604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filipovicha\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "del_cols = ['origin_filename', 'station_time_identifier', 'tc_identifier', 'date_time',\n",
    "            'station_name', 'version', 'correction', 'source_uri', 'station_identifier', '_merge']\n",
    "\n",
    "\n",
    "train_real_time.drop(del_cols , axis = 1, inplace=True, errors='ignore') \n",
    "test_real_time.drop(del_cols , axis = 1, inplace=True, errors='ignore') \n",
    "\n",
    "# removing target variable form training set\n",
    "train_real_time.drop('snow_depth_3022_target', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c33bb9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Actual real-Time Train and Test\n",
    "rfc_estimator2 = rfc(n_estimators=1000, \n",
    "                    min_samples_leaf=2, \n",
    "                    n_jobs=7)\n",
    "sampler = ADASYN()\n",
    "clf = make_pipeline(sampler, rfc_estimator2)\n",
    "    \n",
    "rezult = clf.fit(train_real_time, train_y).predict(test_real_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "157daacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-8812fbfd079a>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_real_time['classes'] = classification\n",
      "<ipython-input-29-8812fbfd079a>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_real_time['url'] = url_list\n"
     ]
    }
   ],
   "source": [
    "# merging the prediction/classification to the observations\n",
    "classification = list(rezult)\n",
    "test_real_time['classes'] = classification\n",
    "test_real_time['url'] = url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c55ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "overturn = test_real_time.loc[test_real_time['classes'] == 1]\n",
    "snow_list = overturn['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63431f47",
   "metadata": {},
   "source": [
    "## Detect Wind Speed Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b016a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "common_wind_elems = list(np.intersect1d(Xwind.columns, newDf.columns))\n",
    "test_real_time = newDf[common_wind_elems] \n",
    "common_wind_elems.append('wind_speed_3005_target')\n",
    "train_real_time = Xwind[common_wind_elems]\n",
    "train_y = train_real_time['wind_speed_3005_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b1d03c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_real_time = test_real_time.drop([col for col in test_real_time.columns if test_real_time[col].eq('MSNG').any()], axis=1)\n",
    "common_elems = list(np.intersect1d(test_real_time.columns, train_real_time.columns))\n",
    "common_elems.append('wind_speed_3005_target')\n",
    "train_real_time = train_real_time[common_elems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e027be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_cols = ['origin_filename', 'station_time_identifier', 'tc_identifier', 'date_time',\n",
    "            'station_name', 'version', 'correction', 'source_uri', 'station_identifier', '_merge']\n",
    "\n",
    "\n",
    "train_real_time.drop(del_cols , axis = 1, inplace=True, errors='ignore') \n",
    "test_real_time.drop(del_cols , axis = 1, inplace=True, errors='ignore') \n",
    "\n",
    "# removing target variable form training set\n",
    "train_real_time.drop('wind_speed_3005_target', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2411fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Actual real-Time Train and Test\n",
    "rfc_estimator2 = rfc(n_estimators=1000, \n",
    "                    min_samples_leaf=2, \n",
    "                    n_jobs=7)\n",
    "sampler = ADASYN()\n",
    "clf = make_pipeline(sampler, rfc_estimator2)\n",
    "    \n",
    "rezult = clf.fit(train_real_time, train_y).predict(test_real_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4cb648aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the prediction/classification to the observations\n",
    "classification = list(rezult)\n",
    "test_real_time['classes'] = classification\n",
    "test_real_time['url'] = url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7336e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "overturn = test_real_time.loc[test_real_time['classes'] == 1]\n",
    "wind_list = overturn['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b242f2f7",
   "metadata": {},
   "source": [
    "## Detect Precip Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe428c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_precip_elems = list(np.intersect1d(Xprecip.columns, newDf.columns))\n",
    "test_real_time = newDf[common_precip_elems] \n",
    "common_precip_elems.append('precipitation_amount_285_target')\n",
    "train_real_time = Xprecip[common_precip_elems]\n",
    "train_y = train_real_time['precipitation_amount_285_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5a17597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filipovicha\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "del_cols = ['origin_filename', 'station_time_identifier', 'tc_identifier', 'date_time',\n",
    "            'station_name', 'version', 'correction', 'source_uri', 'station_identifier', '_merge']\n",
    "\n",
    "\n",
    "train_real_time.drop(del_cols , axis = 1, inplace=True, errors='ignore') \n",
    "test_real_time.drop(del_cols , axis = 1, inplace=True, errors='ignore') \n",
    "\n",
    "# removing target variable form training set\n",
    "train_real_time.drop('precipitation_amount_285_target', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3df756d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Actual real-Time Train and Test\n",
    "rfc_estimator2 = rfc(n_estimators=1000, \n",
    "                    min_samples_leaf=2, \n",
    "                    n_jobs=7)\n",
    "sampler = ADASYN()\n",
    "clf = make_pipeline(sampler, rfc_estimator2)\n",
    "    \n",
    "rezult = clf.fit(train_real_time, train_y).predict(test_real_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0eb7cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-8812fbfd079a>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_real_time['classes'] = classification\n",
      "<ipython-input-45-8812fbfd079a>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_real_time['url'] = url_list\n"
     ]
    }
   ],
   "source": [
    "# merging the prediction/classification to the observations\n",
    "classification = list(rezult)\n",
    "test_real_time['classes'] = classification\n",
    "test_real_time['url'] = url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbe360aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "overturn = test_real_time.loc[test_real_time['classes'] == 1]\n",
    "precip_list = overturn['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dcff43",
   "metadata": {},
   "source": [
    "## Present data from list output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "024d6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(source: str):\n",
    "    newstring = source.rsplit('/')\n",
    "    date = newstring[10] \n",
    "    stat = newstring[12]\n",
    "    return [date, stat]\n",
    " \n",
    "def make_dict(sources: list):\n",
    "    dicto = {}\n",
    "    for source in sources:\n",
    "        stat = extract_info(source)[1]\n",
    "        date = extract_info(source)[0]\n",
    "        \n",
    "        #check if stat is in sources:\n",
    "        if stat not in dicto.keys():\n",
    "            dicto[stat] = {'count': 1, 'earliest' : date, 'latest' : date}\n",
    "            \n",
    "        else:\n",
    "            if date < dicto[stat]['earliest']:\n",
    "                dicto[stat]['count'] = dicto[stat]['count'] + 1\n",
    "                dicto[stat]['earliest'] = date\n",
    "                \n",
    "            elif date > dicto[stat]['latest']:\n",
    "                dicto[stat]['count'] = dicto[stat]['count'] + 1\n",
    "                dicto[stat]['latest'] = date\n",
    "                \n",
    "            else:\n",
    "                dicto[stat]['count'] = dicto[stat]['count'] + 1\n",
    "    \n",
    "    return dicto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42e58d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_depth_anomalies = make_dict(snow_list)\n",
    "wind_speed_anomalies = make_dict(wind_list)\n",
    "precip_anomalies = make_dict(precip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78410fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snow Depth Anomalies\n",
      "{'zsm': {'count': 16, 'earliest': '202111122100', 'latest': '202111171600'}, 'xmw': {'count': 14, 'earliest': '202111130000', 'latest': '202111171600'}, 'xmm': {'count': 14, 'earliest': '202111130100', 'latest': '202111170600'}, 'wdc': {'count': 15, 'earliest': '202111122300', 'latest': '202111171600'}, 'wvc': {'count': 6, 'earliest': '202111141100', 'latest': '202111170500'}, 'pqw': {'count': 6, 'earliest': '202111122000', 'latest': '202111170700'}, 'zfs': {'count': 13, 'earliest': '202111122000', 'latest': '202111171300'}, 'wct': {'count': 16, 'earliest': '202111130500', 'latest': '202111171300'}, 'nbi': {'count': 2, 'earliest': '202111140900', 'latest': '202111152000'}, 'wjc': {'count': 2, 'earliest': '202111142300', 'latest': '202111160300'}, 'nco': {'count': 1, 'earliest': '202111161800', 'latest': '202111161800'}, 'xeg': {'count': 1, 'earliest': '202111142000', 'latest': '202111142000'}, 'nek': {'count': 2, 'earliest': '202111122300', 'latest': '202111150200'}, 'pzh': {'count': 1, 'earliest': '202111151700', 'latest': '202111151700'}, 'wvt': {'count': 5, 'earliest': '202111122200', 'latest': '202111141500'}, 'xox': {'count': 1, 'earliest': '202111130800', 'latest': '202111130800'}}\n",
      "Wind Speed Anomalies\n",
      "{'adl': {'count': 126, 'earliest': '202111122000', 'latest': '202111171900'}, 'gah': {'count': 125, 'earliest': '202111122000', 'latest': '202111171900'}, 'pjm': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'wdw': {'count': 126, 'earliest': '202111122000', 'latest': '202111171900'}, 'wvc': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'zka': {'count': 125, 'earliest': '202111122000', 'latest': '202111171900'}, 'apb': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'pif': {'count': 124, 'earliest': '202111122000', 'latest': '202111171900'}, 'wpk': {'count': 124, 'earliest': '202111122000', 'latest': '202111171900'}, 'xgd': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'pzh': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'zcr': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'xtl': {'count': 124, 'earliest': '202111122000', 'latest': '202111171900'}, 'pqw': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'erm': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'wgr': {'count': 124, 'earliest': '202111122000', 'latest': '202111171900'}, 'wkx': {'count': 124, 'earliest': '202111122000', 'latest': '202111171900'}, 'vqz': {'count': 124, 'earliest': '202111122000', 'latest': '202111171900'}, 'wxp': {'count': 125, 'earliest': '202111122000', 'latest': '202111171900'}, 'wst': {'count': 125, 'earliest': '202111121900', 'latest': '202111171900'}, 'wzt': {'count': 124, 'earliest': '202111122000', 'latest': '202111171900'}, 'xzv': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'xwf': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'wzg': {'count': 124, 'earliest': '202111122000', 'latest': '202111171900'}, 'wdv': {'count': 124, 'earliest': '202111122000', 'latest': '202111171900'}, 'abf': {'count': 124, 'earliest': '202111122000', 'latest': '202111171900'}, 'wct': {'count': 124, 'earliest': '202111122000', 'latest': '202111171900'}, 'zcy': {'count': 124, 'earliest': '202111122000', 'latest': '202111171900'}, 'zvm': {'count': 118, 'earliest': '202111122000', 'latest': '202111171300'}, 'wdc': {'count': 124, 'earliest': '202111122000', 'latest': '202111171900'}, 'zlt': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'who': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'wfp': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'wij': {'count': 103, 'earliest': '202111122000', 'latest': '202111171900'}, 'wnv': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'xfb': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}}\n",
      "Precip Anomalies\n",
      "{'zlt': {'count': 123, 'earliest': '202111122000', 'latest': '202111171900'}, 'wic': {'count': 102, 'earliest': '202111122000', 'latest': '202111162200'}}\n"
     ]
    }
   ],
   "source": [
    "print('Snow Depth Anomalies')\n",
    "print(snow_depth_anomalies)\n",
    "\n",
    "print('Wind Speed Anomalies')\n",
    "print(wind_speed_anomalies)\n",
    "\n",
    "print('Precip Anomalies')\n",
    "print(precip_anomalies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
